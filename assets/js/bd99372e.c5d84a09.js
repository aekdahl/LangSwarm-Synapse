"use strict";(self.webpackChunkdocusaurus_docs=self.webpackChunkdocusaurus_docs||[]).push([[338],{6404:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>c,frontMatter:()=>o,metadata:()=>s,toc:()=>p});const s=JSON.parse('{"id":"Tutorials/voting","title":"Voting with a LangChain","description":"This tutorial demonstrates how to use LangSwarm\'s LLMVoting within a LangChain pipeline. By leveraging LangSwarm\u2019s voting capabilities, we can select the best response from multiple agents and process the selected response in LangChain for further refinement.","source":"@site/docs/Tutorials/voting.md","sourceDirName":"Tutorials","slug":"/Tutorials/voting","permalink":"/LangSwarm/Tutorials/voting","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":104,"frontMatter":{"title":"Voting with a LangChain","sidebar_position":104},"sidebar":"defaultSidebar","previous":{"title":"Routing with a LangChain","permalink":"/LangSwarm/Tutorials/routing"},"next":{"title":"Logging in LangSwarm","permalink":"/LangSwarm/logging/"}}');var t=i(4848),r=i(8453);const o={title:"Voting with a LangChain",sidebar_position:104},a="Voting with a LangChain",l={},p=[{value:"<strong>Prerequisites</strong>",id:"prerequisites",level:2},{value:"<strong>Overview</strong>",id:"overview",level:2},{value:"<strong>Full Code</strong>",id:"full-code",level:2},{value:"<strong>Code Walkthrough</strong>",id:"code-walkthrough",level:2},{value:"<strong>Step 1: Pre-processing Chain</strong>",id:"step-1-pre-processing-chain",level:3},{value:"<strong>Step 2: Voting Chain</strong>",id:"step-2-voting-chain",level:3},{value:"<strong>Step 3: Post-processing Chain</strong>",id:"step-3-post-processing-chain",level:3},{value:"<strong>Step 4: Build and Run the Pipeline</strong>",id:"step-4-build-and-run-the-pipeline",level:3},{value:"<strong>Expected Output</strong>",id:"expected-output",level:2},{value:"<strong>Why This is Powerful</strong>",id:"why-this-is-powerful",level:2}];function h(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"voting-with-a-langchain",children:"Voting with a LangChain"})}),"\n",(0,t.jsxs)(n.p,{children:["This tutorial demonstrates how to use ",(0,t.jsx)(n.strong,{children:"LangSwarm's LLMVoting"})," within a LangChain pipeline. By leveraging LangSwarm\u2019s voting capabilities, we can select the best response from multiple agents and process the selected response in LangChain for further refinement."]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"prerequisites",children:(0,t.jsx)(n.strong,{children:"Prerequisites"})}),"\n",(0,t.jsx)(n.p,{children:"Ensure you have the necessary libraries installed:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"pip install langswarm langchain langchain-openai transformers\n"})}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"overview",children:(0,t.jsx)(n.strong,{children:"Overview"})}),"\n",(0,t.jsx)(n.p,{children:"We will:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["Use LangChain\u2019s ",(0,t.jsx)(n.code,{children:"LLMChain"})," for pre-processing input."]}),"\n",(0,t.jsxs)(n.li,{children:["Utilize LangSwarm\u2019s ",(0,t.jsx)(n.code,{children:"LLMVotingChain"})," to vote on responses from multiple agents."]}),"\n",(0,t.jsx)(n.li,{children:"Integrate a post-processing step with LangChain to refine the selected response."}),"\n",(0,t.jsxs)(n.li,{children:["Combine all steps into a LangChain ",(0,t.jsx)(n.code,{children:"SequentialChain"})," pipeline for a unified workflow."]}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"full-code",children:(0,t.jsx)(n.strong,{children:"Full Code"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'"""\nLangSwarm + LangChain Pipeline Tutorial: Voting Swarm\n\nThis tutorial demonstrates how to use LangSwarm\'s LangChain-compatible tools\nto include `LLMVoting` directly in a LangChain pipeline with pre- and post-processing steps.\n\nKey Features:\n- Use LangSwarm\u2019s built-in LangChain-compatible voting chain.\n- Pre-processing and post-processing steps in the pipeline.\n- Select the best response from multiple agents using a voting mechanism.\n"""\n\n# Import necessary libraries\nfrom langswarm.chains import LLMVotingChain  # LangSwarm\'s LangChain-compatible voting chain\nfrom langchain.prompts import PromptTemplate  # LangChain prompt templates\nfrom langchain.chains import SequentialChain, LLMChain  # LangChain pipeline framework\nfrom langchain.llms import OpenAI  # LangChain OpenAI LLM\n\n# Step 1: Pre-processing Chain\n"""\nThe pre-processing chain ensures the input is clean and formatted before voting.\n"""\npre_prompt = PromptTemplate(\n    input_variables=["raw_input"],\n    template="Clean and standardize the following input for analysis:\\n\\n{raw_input}"\n)\npre_chain = LLMChain(llm=OpenAI(model="gpt-3.5-turbo"), prompt=pre_prompt)\n\n# Step 2: Voting Chain\n"""\nUse LangSwarm\'s LangChain-compatible `LLMVotingChain` to select the best response\nfrom multiple agents.\n"""\nvoting_chain = LLMVotingChain(\n    agents=[\n        {"model": "gpt-4", "api_key": "your_openai_api_key"},\n        {"model": "gpt-3.5-turbo", "api_key": "your_openai_api_key"},\n        {"model": "gpt-3.5-turbo-instruct", "api_key": "your_openai_api_key"},\n    ]\n)\n\n# Step 3: Post-processing Chain\n"""\nThe post-processing chain refines the voted response and generates actionable insights.\n"""\npost_prompt = PromptTemplate(\n    input_variables=["voted_response"],\n    template=(\n        "Based on the selected response:\\n\\n"\n        "{voted_response}\\n\\n"\n        "Provide three actionable recommendations to address the topic."\n    )\n)\npost_chain = LLMChain(llm=OpenAI(model="gpt-3.5-turbo"), prompt=post_prompt)\n\n# Step 4: Build the LangChain Pipeline\n"""\nCombine the pre-processing, voting, and post-processing steps into a LangChain pipeline.\n"""\npipeline = SequentialChain(\n    chains=[pre_chain, voting_chain, post_chain],\n    input_variables=["raw_input"],\n    output_variables=["voted_response", "recommendations"],\n)\n\n# Step 5: Run the Pipeline\n"""\nRun the pipeline on a query, demonstrating the complete multi-agent workflow.\n"""\nquery = "What are the key benefits of remote work?"\nresults = pipeline.run({"raw_input": query})\n\n# Display the results\nprint("\\nVoted Response:", results["voted_response"])\nprint("\\nRecommendations:", results["recommendations"])\n'})}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"code-walkthrough",children:(0,t.jsx)(n.strong,{children:"Code Walkthrough"})}),"\n",(0,t.jsx)(n.h3,{id:"step-1-pre-processing-chain",children:(0,t.jsx)(n.strong,{children:"Step 1: Pre-processing Chain"})}),"\n",(0,t.jsxs)(n.p,{children:["The pre-processing chain formats the input query to ensure it is standardized before being passed to the voting swarm. This step uses LangChain\u2019s ",(0,t.jsx)(n.code,{children:"LLMChain"}),"."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'pre_prompt = PromptTemplate(\n    input_variables=["raw_input"],\n    template="Clean and standardize the following input for analysis:\\n\\n{raw_input}"\n)\npre_chain = LLMChain(llm=OpenAI(model="gpt-3.5-turbo"), prompt=pre_prompt)\n'})}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h3,{id:"step-2-voting-chain",children:(0,t.jsx)(n.strong,{children:"Step 2: Voting Chain"})}),"\n",(0,t.jsxs)(n.p,{children:["LangSwarm\u2019s ",(0,t.jsx)(n.code,{children:"LLMVotingChain"})," queries multiple agents and selects the best response using a voting mechanism. This ensures that the output reflects the majority's decision or the highest-quality response."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'voting_chain = LLMVotingChain(\n    agents=[\n        {"model": "gpt-4", "api_key": "your_openai_api_key"},\n        {"model": "gpt-3.5-turbo", "api_key": "your_openai_api_key"},\n        {"model": "gpt-3.5-turbo-instruct", "api_key": "your_openai_api_key"},\n    ]\n)\n'})}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h3,{id:"step-3-post-processing-chain",children:(0,t.jsx)(n.strong,{children:"Step 3: Post-processing Chain"})}),"\n",(0,t.jsx)(n.p,{children:"The post-processing chain refines the selected response and generates actionable recommendations based on the voted output."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'post_prompt = PromptTemplate(\n    input_variables=["voted_response"],\n    template=(\n        "Based on the selected response:\\n\\n"\n        "{voted_response}\\n\\n"\n        "Provide three actionable recommendations to address the topic."\n    )\n)\npost_chain = LLMChain(llm=OpenAI(model="gpt-3.5-turbo"), prompt=post_prompt)\n'})}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h3,{id:"step-4-build-and-run-the-pipeline",children:(0,t.jsx)(n.strong,{children:"Step 4: Build and Run the Pipeline"})}),"\n",(0,t.jsx)(n.p,{children:"The pipeline combines all steps\u2014pre-processing, voting, and post-processing\u2014into a unified LangChain workflow. The query is processed, the best response is selected via voting, and actionable recommendations are generated."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'pipeline = SequentialChain(\n    chains=[pre_chain, voting_chain, post_chain],\n    input_variables=["raw_input"],\n    output_variables=["voted_response", "recommendations"],\n)\n\nquery = "What are the key benefits of remote work?"\nresults = pipeline.run({"raw_input": query})\n\nprint("\\nVoted Response:", results["voted_response"])\nprint("\\nRecommendations:", results["recommendations"])\n'})}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"expected-output",children:(0,t.jsx)(n.strong,{children:"Expected Output"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-plaintext",children:"Voted Response:\nRemote work increases productivity, enhances work-life balance, and reduces commuting-related stress.\n\nRecommendations:\n1. Implement flexible scheduling policies to maximize productivity.\n2. Provide remote work resources, such as ergonomic equipment and IT support.\n3. Encourage regular team check-ins to maintain collaboration and morale.\n"})}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"why-this-is-powerful",children:(0,t.jsx)(n.strong,{children:"Why This is Powerful"})}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Democratic Decision-Making"}),":"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Selects the best response using a robust voting mechanism among multiple agents."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Seamless Integration"}),":"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Combines LangSwarm\u2019s voting capabilities with LangChain for post-processing."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Scalability"}),":"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Easily add more agents or refine the pipeline for specific use cases."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["With LangSwarm\u2019s ",(0,t.jsx)(n.code,{children:"LLMVotingChain"}),", you can confidently select the best outputs from multiple agents and refine them in LangChain workflows for actionable results."]})]})}function c(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(h,{...e})}):h(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>o,x:()=>a});var s=i(6540);const t={},r=s.createContext(t);function o(e){const n=s.useContext(r);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:o(e.components),s.createElement(r.Provider,{value:n},e.children)}}}]);