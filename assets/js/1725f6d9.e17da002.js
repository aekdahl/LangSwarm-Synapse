"use strict";(self.webpackChunkdocusaurus_docs=self.webpackChunkdocusaurus_docs||[]).push([[701],{4612:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>a,contentTitle:()=>l,default:()=>m,frontMatter:()=>t,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"Memory/memory-llm","title":"LangSwarmMemoryLLM","description":"---","source":"@site/docs/Memory/memory-llm.md","sourceDirName":"Memory","slug":"/Memory/memory-llm","permalink":"/LangSwarm/Memory/memory-llm","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":70,"frontMatter":{"title":"LangSwarmMemoryLLM","sidebar_position":70},"sidebar":"defaultSidebar","previous":{"title":"AgentWrapper","permalink":"/LangSwarm/Features/agent-wrapper"},"next":{"title":"LangSwarmAggregationTool","permalink":"/LangSwarm/Tools/aggregation-tool"}}');var o=r(4848),i=r(8453);const t={title:"LangSwarmMemoryLLM",sidebar_position:70},l="LangSwarmMemoryLLM",a={},c=[{value:"<strong>Overview</strong>",id:"overview",level:2},{value:"<strong>Purpose</strong>",id:"purpose",level:2},{value:"<strong>Class Definition</strong>",id:"class-definition",level:2},{value:"<strong>Key Features</strong>",id:"key-features",level:2},{value:"<strong>Parameters</strong>",id:"parameters",level:2},{value:"<strong>Usage</strong>",id:"usage",level:2},{value:"<strong>Customization</strong>",id:"customization",level:2},{value:"<strong>Use Cases</strong>",id:"use-cases",level:2},{value:"<strong>Example Implementation</strong>",id:"example-implementation",level:2},{value:"<strong>Potential Enhancements</strong>",id:"potential-enhancements",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"langswarmmemoryllm",children:"LangSwarmMemoryLLM"})}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"overview",children:(0,o.jsx)(n.strong,{children:"Overview"})}),"\n",(0,o.jsxs)(n.p,{children:["The ",(0,o.jsx)(n.code,{children:"LangSwarmMemoryLLM"})," class extends the base ",(0,o.jsx)(n.code,{children:"LLM"})," class by integrating LangChain-compatible memory, specifically ",(0,o.jsx)(n.code,{children:"ConversationBufferMemory"}),". This allows the model to retain conversational context across queries, enabling more coherent and context-aware interactions."]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"purpose",children:(0,o.jsx)(n.strong,{children:"Purpose"})}),"\n",(0,o.jsxs)(n.p,{children:["The primary purpose of the ",(0,o.jsx)(n.code,{children:"LangSwarmMemoryLLM"})," class is to:"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Enhance Conversational Context"}),": Maintain and utilize a history of queries and responses for multi-turn conversations."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Integrate Memory Management"}),": Seamlessly manage memory with LangChain's ",(0,o.jsx)(n.code,{children:"ConversationBufferMemory"}),"."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Dynamic Query Processing"}),": Allow dynamic query handling with options for resetting, modifying, or erasing memory."]}),"\n"]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"class-definition",children:(0,o.jsx)(n.strong,{children:"Class Definition"})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'from langchain.memory import ConversationBufferMemory\nfrom langswarm.llm import LLM\n\nclass LangSwarmMemoryLLM(LLM):\n    """\n    A LangSwarm LLM with LangChain-compatible memory.\n    """\n    def __init__(self, memory=None, **kwargs):\n        """\n        Initialize the LLM with memory.\n\n        Parameters:\n        - memory (ConversationBufferMemory, optional): LangChain memory object to manage conversational history.\n        - kwargs: Additional parameters for the LLM class.\n        """\n        super().__init__(**kwargs)\n        self.memory = memory or ConversationBufferMemory()\n\n    def chat(self, q=None, json=False, reset=False, erase_query=False, remove_linebreaks=False):\n        """\n        Process a query and store it in memory.\n\n        Parameters:\n        - q (str, optional): The input query string.\n        - json (bool, optional): Placeholder for future use (not utilized in this implementation).\n        - reset (bool, optional): If True, resets the memory before processing the query.\n        - erase_query (bool, optional): If True, excludes the query from being stored in memory.\n        - remove_linebreaks (bool, optional): If True, removes line breaks from the query string.\n\n        Returns:\n        - str: The model\'s response to the input query.\n        """\n        if reset:\n            self.reset()\n\n        if q is not None:\n            self.set_query(q, remove_linebreaks=remove_linebreaks)\n\n        # Retrieve memory context and append it to the query\n        context = self.memory.load_memory_variables({})\n        extended_query = f"{context[\'history\']}\\n{q}" if context else q\n\n        # Generate response\n        response = super().chat(q=extended_query, erase_query=erase_query, remove_linebreaks=remove_linebreaks)\n\n        # Update memory with query and response\n        self.memory.save_context({"input": q}, {"output": response})\n        return response\n'})}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"key-features",children:(0,o.jsx)(n.strong,{children:"Key Features"})}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Memory Integration"}),":"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["Utilizes ",(0,o.jsx)(n.code,{children:"ConversationBufferMemory"})," to store and retrieve conversational history."]}),"\n",(0,o.jsx)(n.li,{children:"Automatically updates memory with each query-response pair."}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Dynamic Memory Management"}),":"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Options to reset or modify memory during interactions."}),"\n",(0,o.jsx)(n.li,{children:"Flexible query handling, including removing line breaks or excluding queries from memory."}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Extended Context"}),":"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Appends the stored conversation history to new queries, enhancing context awareness."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"parameters",children:(0,o.jsx)(n.strong,{children:"Parameters"})}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Initialization Parameters"}),":"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"memory (ConversationBufferMemory, optional)"}),": An optional memory object to manage conversational context. If not provided, a new ",(0,o.jsx)(n.code,{children:"ConversationBufferMemory"})," instance is created."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"kwargs"}),": Additional parameters inherited from the parent ",(0,o.jsx)(n.code,{children:"LLM"})," class."]}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsxs)(n.strong,{children:[(0,o.jsx)(n.code,{children:"chat"})," Method Parameters"]}),":"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"q (str, optional)"}),": The input query to process."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"json (bool, optional)"}),": Placeholder parameter for future use."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"reset (bool, optional)"}),": If ",(0,o.jsx)(n.code,{children:"True"}),", clears the memory before processing the query."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"erase_query (bool, optional)"}),": If ",(0,o.jsx)(n.code,{children:"True"}),", excludes the query from being stored in memory."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"remove_linebreaks (bool, optional)"}),": If ",(0,o.jsx)(n.code,{children:"True"}),", removes line breaks from the input query."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"usage",children:(0,o.jsx)(n.strong,{children:"Usage"})}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Basic Usage"}),":"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'from langchain.memory import ConversationBufferMemory\nfrom mymodule import LangSwarmMemoryLLM\n\n# Initialize LangSwarmMemoryLLM with memory\nmemory_llm = LangSwarmMemoryLLM(memory=ConversationBufferMemory())\n\n# Chat with the model\nresponse1 = memory_llm.chat("What is the capital of France?")\nprint("Response:", response1)  # Expected: "Paris"\n\n# Follow-up query using stored context\nresponse2 = memory_llm.chat("And what is its population?")\nprint("Response:", response2)  # Builds on previous context.\n'})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Resetting Memory"}),":"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'memory_llm.chat("Start a new conversation.", reset=True)\n'})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Erasing Query from Memory"}),":"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'memory_llm.chat("Forget this query.", erase_query=True)\n'})}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"customization",children:(0,o.jsx)(n.strong,{children:"Customization"})}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Custom Memory Object"}),":"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["Replace ",(0,o.jsx)(n.code,{children:"ConversationBufferMemory"})," with a custom memory implementation compatible with LangChain's interface."]}),"\n"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"class CustomMemory(ConversationBufferMemory):\n    # Implement additional functionality\n    pass\n\nmemory_llm = LangSwarmMemoryLLM(memory=CustomMemory())\n"})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Enhanced Context Handling"}),":"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["Modify how historical context is appended to new queries by overriding the ",(0,o.jsx)(n.code,{children:"chat"})," method."]}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Persistent Memory"}),":"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["Extend ",(0,o.jsx)(n.code,{children:"ConversationBufferMemory"})," to persist data in a database or file system."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"use-cases",children:(0,o.jsx)(n.strong,{children:"Use Cases"})}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Chatbots"}),":"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Maintain coherent, multi-turn conversations with context awareness."}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Customer Support Systems"}),":"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Retain user history for personalized responses."}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Task-Oriented Dialogues"}),":"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Enable complex task flows that depend on prior exchanges."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"example-implementation",children:(0,o.jsx)(n.strong,{children:"Example Implementation"})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'if __name__ == "__main__":\n    from langchain.memory import ConversationBufferMemory\n\n    # Initialize memory-enhanced LLM\n    memory_llm = LangSwarmMemoryLLM(memory=ConversationBufferMemory())\n\n    # Sample interaction\n    print(memory_llm.chat("Who is the president of the United States?"))\n    print(memory_llm.chat("What is their political party?"))\n'})}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"potential-enhancements",children:(0,o.jsx)(n.strong,{children:"Potential Enhancements"})}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Memory Limits"}),":"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Add a mechanism to truncate memory when exceeding token limits."}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Searchable Memory"}),":"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Integrate vector-based memory for semantic search capabilities."}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Memory Insights"}),":"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Add methods to visualize or export stored memory for debugging or analysis."}),"\n"]}),"\n"]}),"\n"]})]})}function m(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>t,x:()=>l});var s=r(6540);const o={},i=s.createContext(o);function t(e){const n=s.useContext(i);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:t(e.components),s.createElement(i.Provider,{value:n},e.children)}}}]);