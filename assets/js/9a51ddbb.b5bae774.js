"use strict";(self.webpackChunkdocusaurus_docs=self.webpackChunkdocusaurus_docs||[]).push([[183],{5609:(n,e,a)=>{a.r(e),a.d(e,{assets:()=>o,contentTitle:()=>i,default:()=>m,frontMatter:()=>l,metadata:()=>t,toc:()=>g});const t=JSON.parse('{"id":"Intergrations/llama_index_integration","title":"LlamaIndex","description":"LlamaIndex (formerly GPT Index) enables seamless interaction between Large Language Models (LLMs) and structured/unstructured data sources. With LangSwarm, you can leverage LlamaIndex agents alongside other LLM tools like LangChain, Hugging Face, and OpenAI to orchestrate multi-agent workflows.","source":"@site/docs/Intergrations/llama_index_integration.md","sourceDirName":"Intergrations","slug":"/Intergrations/llama_index_integration","permalink":"/LangSwarm/Intergrations/llama_index_integration","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"LlamaIndex"},"sidebar":"defaultSidebar","previous":{"title":"LangSwarmTemplates","permalink":"/LangSwarm/Interface/templates"},"next":{"title":"Logging in LangSwarm","permalink":"/LangSwarm/Logging/"}}');var r=a(4848),s=a(8453);const l={title:"LlamaIndex"},i="LlamaIndex Integration in LangSwarm",o={},g=[{value:"<strong>Key Features</strong>",id:"key-features",level:2},{value:"<strong>Getting Started</strong>",id:"getting-started",level:2},{value:"<strong>1. Installation</strong>",id:"1-installation",level:3},{value:"<strong>2. Creating a LlamaIndex Agent</strong>",id:"2-creating-a-llamaindex-agent",level:3},{value:"<strong>Using the AgentFactory (Recommended)</strong>",id:"using-the-agentfactory-recommended",level:4},{value:"<strong>Using the AgentWrapper (Advanced Use Case)</strong>",id:"using-the-agentwrapper-advanced-use-case",level:4},{value:"<strong>3. Using Memory with LlamaIndex</strong>",id:"3-using-memory-with-llamaindex",level:3},{value:"<strong>4. Logging LlamaIndex Interactions</strong>",id:"4-logging-llamaindex-interactions",level:3},{value:"<strong>Integration with LangSwarm Features</strong>",id:"integration-with-langswarm-features",level:2},{value:"<strong>1. Multi-Agent Collaboration</strong>",id:"1-multi-agent-collaboration",level:3},{value:"Example: Consensus Workflow with LlamaIndex and LangChain Agents",id:"example-consensus-workflow-with-llamaindex-and-langchain-agents",level:4},{value:"<strong>2. Using LlamaIndex for Data Aggregation</strong>",id:"2-using-llamaindex-for-data-aggregation",level:3},{value:"<strong>3. Shared Memory with LlamaIndex</strong>",id:"3-shared-memory-with-llamaindex",level:3},{value:"<strong>FAQs</strong>",id:"faqs",level:2},{value:"<strong>Q1: Do I need to install LlamaIndex separately?</strong>",id:"q1-do-i-need-to-install-llamaindex-separately",level:3},{value:"<strong>Q2: Can LlamaIndex agents use LangChain memory?</strong>",id:"q2-can-llamaindex-agents-use-langchain-memory",level:3},{value:"<strong>Q3: Does LlamaIndex support LangSmith logging?</strong>",id:"q3-does-llamaindex-support-langsmith-logging",level:3}];function d(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...n.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(e.header,{children:(0,r.jsx)(e.h1,{id:"llamaindex-integration-in-langswarm",children:"LlamaIndex Integration in LangSwarm"})}),"\n",(0,r.jsxs)(e.p,{children:["LlamaIndex (formerly GPT Index) enables seamless interaction between ",(0,r.jsx)(e.strong,{children:"Large Language Models (LLMs)"})," and structured/unstructured data sources. With LangSwarm, you can leverage ",(0,r.jsx)(e.strong,{children:"LlamaIndex"})," agents alongside other LLM tools like LangChain, Hugging Face, and OpenAI to orchestrate multi-agent workflows."]}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h2,{id:"key-features",children:(0,r.jsx)(e.strong,{children:"Key Features"})}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Index-Based Data Retrieval"}),":","\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Integrate LlamaIndex to query structured or unstructured datasets seamlessly."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Memory Compatibility"}),":","\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Supports both LangSwarm's internal memory and LangChain memory for managing context."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Unified Logging"}),":","\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Logs interactions with LlamaIndex agents to LangSmith (if enabled) or Python's logging system."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Interoperability"}),":","\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Use LlamaIndex agents alongside other LangSwarm agents for consensus, voting, or aggregation workflows."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h2,{id:"getting-started",children:(0,r.jsx)(e.strong,{children:"Getting Started"})}),"\n",(0,r.jsx)(e.h3,{id:"1-installation",children:(0,r.jsx)(e.strong,{children:"1. Installation"})}),"\n",(0,r.jsx)(e.p,{children:"To use LlamaIndex with LangSwarm, ensure the following dependencies are installed:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-bash",children:"pip install langswarm llama-index\n"})}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h3,{id:"2-creating-a-llamaindex-agent",children:(0,r.jsx)(e.strong,{children:"2. Creating a LlamaIndex Agent"})}),"\n",(0,r.jsx)(e.h4,{id:"using-the-agentfactory-recommended",children:(0,r.jsx)(e.strong,{children:"Using the AgentFactory (Recommended)"})}),"\n",(0,r.jsxs)(e.p,{children:["The ",(0,r.jsx)(e.code,{children:"AgentFactory"})," provides a simple and consistent way to create agents, including LlamaIndex."]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from langswarm.factory import AgentFactory\n\n# Create a LlamaIndex agent using the AgentFactory\nllama_agent = AgentFactory.create(\n    name="LlamaAgent",\n    agent_type="llamaindex",\n    documents=["LangSwarm is a Python package for orchestrating multiple LLMs."],\n)\n\n# Query the agent\nresponse = llama_agent.chat("What is LangSwarm?")\nprint(response)\n# Expected Output: "LangSwarm is a Python package for orchestrating multiple LLMs."\n'})}),"\n",(0,r.jsx)(e.h4,{id:"using-the-agentwrapper-advanced-use-case",children:(0,r.jsx)(e.strong,{children:"Using the AgentWrapper (Advanced Use Case)"})}),"\n",(0,r.jsxs)(e.p,{children:["For advanced users who need more control, the ",(0,r.jsx)(e.code,{children:"AgentWrapper"})," can be used directly."]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from langswarm.wrappers.agent_wrapper import AgentWrapper\n\n# Advanced: Directly wrap a LlamaIndex agent\nllama_agent = AgentWrapper(\n    name="LlamaAgent",\n    agent="llamaindex",\n    documents=["LangSwarm is a Python package for orchestrating multiple LLMs."],\n)\n\n# Query the agent\nresponse = llama_agent.chat("What is LangSwarm?")\nprint(response)\n# Expected Output: "LangSwarm is a Python package for orchestrating multiple LLMs."\n'})}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h3,{id:"3-using-memory-with-llamaindex",children:(0,r.jsx)(e.strong,{children:"3. Using Memory with LlamaIndex"})}),"\n",(0,r.jsx)(e.p,{children:"LangSwarm provides flexible memory handling:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Agent-Specific Memory"}),": Automatically uses the memory provided by the agent (if available)."]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Custom Memory"}),": Pass a memory instance to the ",(0,r.jsx)(e.code,{children:"AgentFactory"})," or ",(0,r.jsx)(e.code,{children:"AgentWrapper"}),"."]}),"\n"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from langchain.memory import ConversationBufferMemory\nfrom langswarm.factory import AgentFactory\n\n# Create a memory instance\nmemory = ConversationBufferMemory()\n\n# Create a LlamaIndex agent with memory using the AgentFactory\nllama_agent = AgentFactory.create(\n    name="LlamaAgent",\n    agent_type="llamaindex",\n    documents=[\n        "LangSwarm is a Python package for orchestrating multiple LLMs.",\n        "LlamaIndex is a library for connecting LLMs to data sources.",\n    ],\n    memory=memory,\n)\n\n# Query the agent with memory support\nresponse1 = llama_agent.chat("What is LangSwarm?")\nresponse2 = llama_agent.chat("What is LlamaIndex?")\nprint(response1)\nprint(response2)\n# Memory ensures both responses have relevant context.\n'})}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h3,{id:"4-logging-llamaindex-interactions",children:(0,r.jsx)(e.strong,{children:"4. Logging LlamaIndex Interactions"})}),"\n",(0,r.jsx)(e.p,{children:"LangSwarm supports unified logging:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"LangSmith Integration"}),": Logs queries and responses to LangSmith when configured."]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Fallback Logging"}),": Logs to Python's logging system if LangSmith is not available."]}),"\n"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'# Enable LangSmith logging by providing an API key\nllama_agent = AgentFactory.create(\n    name="LlamaAgent",\n    agent_type="llamaindex",\n    documents=["LangSwarm documentation.", "LlamaIndex guides."],\n    langsmith_api_key="your-langsmith-api-key",\n)\n\n# Query the agent and log the interaction\nresponse = llama_agent.chat("What is LlamaIndex?")\n'})}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h2,{id:"integration-with-langswarm-features",children:(0,r.jsx)(e.strong,{children:"Integration with LangSwarm Features"})}),"\n",(0,r.jsx)(e.h3,{id:"1-multi-agent-collaboration",children:(0,r.jsx)(e.strong,{children:"1. Multi-Agent Collaboration"})}),"\n",(0,r.jsx)(e.p,{children:"LlamaIndex agents can participate in LangSwarm workflows like consensus or aggregation."}),"\n",(0,r.jsx)(e.h4,{id:"example-consensus-workflow-with-llamaindex-and-langchain-agents",children:"Example: Consensus Workflow with LlamaIndex and LangChain Agents"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from langswarm.tools import LLMConsensus\nfrom langswarm.factory import AgentFactory\n\n# Create agents using the AgentFactory\nllama_agent = AgentFactory.create(\n    name="LlamaAgent",\n    agent_type="llamaindex",\n    documents=["LangSwarm is a Python package."],\n)\nlangchain_agent = AgentFactory.create(\n    name="LangChainAgent",\n    agent_type="langchain",\n    model="gpt-3.5-turbo",\n)\n\n# Combine agents for consensus\nconsensus_tool = LLMConsensus(query="What is LangSwarm?", clients=[langchain_agent, llama_agent])\nresponse = consensus_tool.run()\nprint(response)\n# Expected Output: "LangSwarm is a Python package."\n'})}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h3,{id:"2-using-llamaindex-for-data-aggregation",children:(0,r.jsx)(e.strong,{children:"2. Using LlamaIndex for Data Aggregation"})}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from langswarm.tools import LLMAggregation\nfrom langswarm.factory import AgentFactory\n\n# Create a LlamaIndex agent\nllama_agent = AgentFactory.create(\n    name="LlamaAgent",\n    agent_type="llamaindex",\n    documents=["LangSwarm supports LlamaIndex."],\n)\n\n# Aggregate data from multiple queries\naggregation_tool = LLMAggregation(query="Tell me about LangSwarm.", clients=[llama_agent])\nresponse = aggregation_tool.run()\nprint(response)\n# Expected Output: Aggregated data from LlamaIndex.\n'})}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h3,{id:"3-shared-memory-with-llamaindex",children:(0,r.jsx)(e.strong,{children:"3. Shared Memory with LlamaIndex"})}),"\n",(0,r.jsx)(e.p,{children:"Enable shared memory by providing the same memory instance to multiple agents:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from langchain.memory import ConversationBufferMemory\nfrom langswarm.factory import AgentFactory\n\n# Shared memory instance\nshared_memory = ConversationBufferMemory()\n\n# Create two agents with shared memory\nagent1 = AgentFactory.create(\n    name="Agent1",\n    agent_type="llamaindex",\n    documents=["Document 1"],\n    memory=shared_memory,\n)\nagent2 = AgentFactory.create(\n    name="Agent2",\n    agent_type="llamaindex",\n    documents=["Document 2"],\n    memory=shared_memory,\n)\n\n# Query both agents with shared context\nresponse1 = agent1.chat("What is Document 1?")\nresponse2 = agent2.chat("What is Document 2?")\nprint(response1)\nprint(response2)\n'})}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h2,{id:"faqs",children:(0,r.jsx)(e.strong,{children:"FAQs"})}),"\n",(0,r.jsx)(e.h3,{id:"q1-do-i-need-to-install-llamaindex-separately",children:(0,r.jsx)(e.strong,{children:"Q1: Do I need to install LlamaIndex separately?"})}),"\n",(0,r.jsxs)(e.p,{children:["Yes. Install it using ",(0,r.jsx)(e.code,{children:"pip install llama-index"}),"."]}),"\n",(0,r.jsx)(e.h3,{id:"q2-can-llamaindex-agents-use-langchain-memory",children:(0,r.jsx)(e.strong,{children:"Q2: Can LlamaIndex agents use LangChain memory?"})}),"\n",(0,r.jsxs)(e.p,{children:["Yes. Provide a ",(0,r.jsx)(e.code,{children:"ConversationBufferMemory"})," or another memory class when wrapping the agent."]}),"\n",(0,r.jsx)(e.h3,{id:"q3-does-llamaindex-support-langsmith-logging",children:(0,r.jsx)(e.strong,{children:"Q3: Does LlamaIndex support LangSmith logging?"})}),"\n",(0,r.jsx)(e.p,{children:"Yes. If LangSmith is configured, LlamaIndex interactions are logged automatically."}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.p,{children:"Let me know if you'd like further refinements!"})]})}function m(n={}){const{wrapper:e}={...(0,s.R)(),...n.components};return e?(0,r.jsx)(e,{...n,children:(0,r.jsx)(d,{...n})}):d(n)}},8453:(n,e,a)=>{a.d(e,{R:()=>l,x:()=>i});var t=a(6540);const r={},s=t.createContext(r);function l(n){const e=t.useContext(s);return t.useMemo((function(){return"function"==typeof n?n(e):{...e,...n}}),[e,n])}function i(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(r):n.components||r:l(n.components),t.createElement(s.Provider,{value:e},n.children)}}}]);